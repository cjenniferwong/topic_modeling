{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling and Recommending Similar Stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T00:54:10.441008Z",
     "start_time": "2020-03-11T00:54:09.275540Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "random_state=42 # to make sure its reproducible\n",
    "\n",
    "from glob import glob\n",
    "datafiles = glob('data/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T00:54:11.383619Z",
     "start_time": "2020-03-11T00:54:10.531334Z"
    }
   },
   "outputs": [],
   "source": [
    "# packages for preprocessing text\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# packages for topic modeling\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# loading custom function to display topic vocab\n",
    "from custom_functions import display_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T00:54:13.847728Z",
     "start_time": "2020-03-11T00:54:13.807996Z"
    }
   },
   "outputs": [],
   "source": [
    "# loading the data\n",
    "stories_data = pd.read_csv(datafiles[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the column names to make it easier to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T00:54:14.444179Z",
     "start_time": "2020-03-11T00:54:14.417049Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2014 entries, 0 to 2060\n",
      "Data columns (total 8 columns):\n",
      "story_id        2014 non-null int64\n",
      "perspective     2014 non-null object\n",
      "age             1548 non-null float64\n",
      "lgbtq           1548 non-null object\n",
      "race            1548 non-null object\n",
      "topic           2014 non-null object\n",
      "published_at    819 non-null object\n",
      "story_texts     2013 non-null object\n",
      "dtypes: float64(1), int64(1), object(6)\n",
      "memory usage: 141.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# dropping duplicates if the text are the same\n",
    "stories_data.drop_duplicates(subset=['Story texts'], inplace=True)\n",
    "\n",
    "# renaming columns to make them easier to work with\n",
    "drop_columns = [column for column in stories_data.columns if 'link' in column.lower()]\n",
    "drop_columns.extend([ 'Title', 'Lede', 'Cringey', 'Haha', 'Me too', 'Interesting', 'Phone', 'Like'])\n",
    "stories_data.drop(columns=drop_columns, inplace=True, errors='ignore')\n",
    "\n",
    "stories_data.columns = [column.lower().replace(' ', '_') for column in stories_data.columns]\n",
    "stories_data.rename(columns={\n",
    "    'id':'story_id'\n",
    "}, inplace=True)\n",
    "stories_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T00:54:14.742257Z",
     "start_time": "2020-03-11T00:54:14.710197Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "story_id           0\n",
       "perspective        0\n",
       "age              466\n",
       "lgbtq            466\n",
       "race             466\n",
       "topic              0\n",
       "published_at    1195\n",
       "story_texts        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many are missing data\n",
    "stories_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T00:54:15.138925Z",
     "start_time": "2020-03-11T00:54:15.112736Z"
    }
   },
   "outputs": [],
   "source": [
    "# dropping the row that doenst have data for the text column since we're using the text column heavily\n",
    "stories_data.dropna(subset=['story_texts'], inplace=True)\n",
    "\n",
    "# resetting index since i dropped rows earlier\n",
    "stories_data.reset_index(inplace=True)\n",
    "stories_data.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Text\n",
    "\n",
    "1. lemmatizing the text\n",
    "2. removing stop words\n",
    "4. create n_grams\n",
    "3. vectorizing the words to feed to the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T00:54:22.938199Z",
     "start_time": "2020-03-11T00:54:15.714416Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stories_data['cleaned'] = stories_data.story_texts.str.replace('[^\\w\\s]','')\n",
    "\n",
    "# getting the POS tags to feed to the lem\n",
    "stories_data['pos_tagged'] = stories_data.cleaned.map(word_tokenize).map(pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T00:54:26.888729Z",
     "start_time": "2020-03-11T00:54:24.903550Z"
    }
   },
   "outputs": [],
   "source": [
    "lem = WordNetLemmatizer()\n",
    "stories_data['lemmed'] = stories_data['pos_tagged'].map(lambda x: [lem.lemmatize(word, tag[0].lower()) for word, tag in x if tag[0].lower() in ['a', 'v', 'r', 'n']])\n",
    "stories_data.lemmed = stories_data.lemmed.map(lambda x: ' '.join(word for word in x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling with different algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T00:54:28.878480Z",
     "start_time": "2020-03-11T00:54:28.869453Z"
    }
   },
   "outputs": [],
   "source": [
    "# transforming the stop words in the same pattern that the text is being processed as \n",
    "stop_words = stopwords.words('english')\n",
    "stop_words = [s.translate(str.maketrans('', '', string.punctuation)) for s in stop_words]\n",
    "\n",
    "# additional stop words removing from corpus\n",
    "additional_stop_words = ['im', 'idk', 'friend', 'nothing', 'meh'\n",
    "                         , 'ha', 'hey', 'hi', 'ive', 'vjfjfjfc', 'umm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T00:54:31.120948Z",
     "start_time": "2020-03-11T00:54:30.881025Z"
    }
   },
   "outputs": [],
   "source": [
    "#tfidf vectorizer\n",
    "tfidf = TfidfVectorizer(stop_words=stop_words + additional_stop_words\n",
    "                        , lowercase=True\n",
    "                       , ngram_range=(1,2))\n",
    "\n",
    "# document term matrix \n",
    "tfidf_dtm = tfidf.fit_transform(stories_data.lemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T00:54:33.143801Z",
     "start_time": "2020-03-11T00:54:33.139854Z"
    }
   },
   "outputs": [],
   "source": [
    "# tfidf_nmf.components_ # an array like a dictionary with words and values aka the h component matrix lol "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T00:54:36.573448Z",
     "start_time": "2020-03-11T00:54:35.145664Z"
    }
   },
   "outputs": [],
   "source": [
    "n_components=9\n",
    "tfidf_nmf = NMF(n_components=n_components\n",
    "            , random_state=random_state)\n",
    "tfidf_nmf_data = tfidf_nmf.fit_transform(tfidf_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T00:54:38.603753Z",
     "start_time": "2020-03-11T00:54:38.548285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "tell, say, want, go, school, mom, tell tell, come, day, anyone\n",
      "\n",
      "Topic  1\n",
      "sex, sex sex, want, want sex, boyfriend, sex want, sex say, sexy, bad, keyon\n",
      "\n",
      "Topic  2\n",
      "good, good girl, room good, room, girl good, good act, dick, hello, home good, good guy\n",
      "\n",
      "Topic  3\n",
      "get, period, go, start, puberty, get period, mom, go puberty, hair, bathroom\n",
      "\n",
      "Topic  4\n",
      "make, feel, felt, people, make feel, really, well, think, look, way\n",
      "\n",
      "Topic  5\n",
      "know, know know, want, want know, know feel, know relationship, know say, feel, bye, really know\n",
      "\n",
      "Topic  6\n",
      "ask, say, consent, ask consent, yes, fuck, say yes, boyfriend, question, ask say\n",
      "\n",
      "Topic  7\n",
      "girl, like, like girl, girl school, gender, boy, dress, question, good girl, act\n",
      "\n",
      "Topic  8\n",
      "date, talk, like, love, guy, start, break, relationship, want, still\n"
     ]
    }
   ],
   "source": [
    "# note to self: it seems like stop words are removed before n grams are created\n",
    "# need to check source code to make sure\n",
    "# i wonder if you can modifer the sihoette score for topic modeling\n",
    "\n",
    "display_topics(tfidf_nmf, tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T00:54:42.404661Z",
     "start_time": "2020-03-11T00:54:42.394784Z"
    }
   },
   "outputs": [],
   "source": [
    "m, n = tfidf_nmf_data.shape\n",
    "tfidf_nmf_df = pd.DataFrame(tfidf_nmf_data, columns=[f'topic_{num}' for num in range(n)])\n",
    "tfidf_nmf_df['max_topic'] = tfidf_nmf_data.argmax(axis=1)\n",
    "# tfidf_nmf_df['max_topic'].value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T00:54:44.715684Z",
     "start_time": "2020-03-11T00:54:44.704022Z"
    }
   },
   "outputs": [],
   "source": [
    "combined = pd.merge(stories_data, tfidf_nmf_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figuring out what the topics actually mean by looking at the stories\n",
    "\n",
    "sorting the stories by the highest ranking to figure out what the topics mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T00:44:16.450365Z",
     "start_time": "2020-03-11T00:44:16.409672Z"
    }
   },
   "outputs": [],
   "source": [
    "# dictionary to map the topics numbers and the defined topic names\n",
    "topics = {}\n",
    "combined.sort_values(by='topic_0', ascending=False).head(n_top)['story_texts'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T00:44:16.460135Z",
     "start_time": "2020-03-11T00:44:16.454601Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating a function instead of just copying and pasting code\n",
    "def top_n_docs(df, sorting_column, text_column, n_top=1):\n",
    "    '''\n",
    "    pass in the dataframe, the column that you're sorting values by, the number of top docs to print\n",
    "    , and the column name that has the text values\n",
    "    \n",
    "    returns a list of values that follow these parameters\n",
    "    '''\n",
    "    return df.sort_values(by=sorting_column, ascending=False).head(n_top)[text_column].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T00:44:33.530838Z",
     "start_time": "2020-03-11T00:44:33.520280Z"
    }
   },
   "outputs": [],
   "source": [
    "topics['topic_0'] = 'interpersonal_relationships_conversations' # venting and advice\n",
    "\n",
    "top_n_docs(combined, 'topic_1', 'story_texts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T21:57:53.440664Z",
     "start_time": "2020-03-10T21:57:53.415194Z"
    }
   },
   "outputs": [],
   "source": [
    "topics['topic_1'] = 'the word sex'\n",
    "top_n_docs(combined, 'topic_2', 'story_texts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T21:57:53.454035Z",
     "start_time": "2020-03-10T21:57:53.444943Z"
    }
   },
   "outputs": [],
   "source": [
    "topics['topic_2'] = 'app_confusion'\n",
    "top_n_docs(combined, 'topic_3', 'story_texts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T21:57:53.468890Z",
     "start_time": "2020-03-10T21:57:53.458190Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "topics['topic_3'] = 'puberty' # first period\n",
    "top_n_docs(combined, 'topic_4', 'story_texts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T21:57:53.483919Z",
     "start_time": "2020-03-10T21:57:53.472658Z"
    }
   },
   "outputs": [],
   "source": [
    "topics['topic_4'] = 'feeling_judged' # social relationships\n",
    "top_n_docs(combined, 'topic_5', 'story_texts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T21:57:53.499053Z",
     "start_time": "2020-03-10T21:57:53.489613Z"
    }
   },
   "outputs": [],
   "source": [
    "topics['topic_5'] = 'i_dont_know'\n",
    "top_n_docs(combined, 'topic_6', 'story_texts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T21:57:53.516090Z",
     "start_time": "2020-03-10T21:57:53.502576Z"
    }
   },
   "outputs": [],
   "source": [
    "topics['topic_6'] = 'consent_and_sex'\n",
    "top_n_docs(combined, 'topic_7', 'story_texts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T21:57:53.536218Z",
     "start_time": "2020-03-10T21:57:53.521412Z"
    }
   },
   "outputs": [],
   "source": [
    "topics['topic_7'] = 'being_a_girl'\n",
    "top_n_docs(combined, 'topic_8', 'story_texts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T21:57:53.548506Z",
     "start_time": "2020-03-10T21:57:53.539890Z"
    }
   },
   "outputs": [],
   "source": [
    "topics['topic_8'] = 'dating_and_relationships'\n",
    "\n",
    "# renaming the columns to make more intuitive sense \n",
    "combined.rename(columns=topics, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommending similar stories based on their topic modeling scores\n",
    "\n",
    "Now that we have different features to compare the stories along different dimensions, can we generate recommendations based on how similar stories are to each other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T21:57:53.849435Z",
     "start_time": "2020-03-10T21:57:53.550817Z"
    }
   },
   "outputs": [],
   "source": [
    "cosine_scores = cosine_similarity(tfidf_nmf_data, tfidf_nmf_data)\n",
    "\n",
    "# have to get the second most similar since the most similar would be with itself and we dont want that lol\n",
    "combined['most_similar_index'] = cosine_scores.argsort()[:, -2] \n",
    "# combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T21:57:53.866775Z",
     "start_time": "2020-03-10T21:57:53.853280Z"
    }
   },
   "outputs": [],
   "source": [
    "# wow a self join have the most similar story in the same row to make it easier to compare\n",
    "self_joined = pd.merge(combined, combined['story_texts'], left_on='most_similar_index', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T21:57:54.202183Z",
     "start_time": "2020-03-10T21:57:53.869598Z"
    }
   },
   "outputs": [],
   "source": [
    "# there are a few stories that are deemed to be most similar to lots of other stories\n",
    "sns.distplot(combined.most_similar_index.value_counts());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T21:57:54.219605Z",
     "start_time": "2020-03-10T21:57:54.206932Z"
    }
   },
   "outputs": [],
   "source": [
    "random_sample = self_joined[~self_joined.published_at.isna()].sample(n=10\n",
    "                   , random_state=random_state)\n",
    "# random_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T21:57:54.257268Z",
     "start_time": "2020-03-10T21:57:54.238748Z"
    }
   },
   "outputs": [],
   "source": [
    "# checking a recommended story\n",
    "random_sample[['story_texts_x', 'story_texts_y']].head(1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are there patterns with these topics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T21:58:09.832625Z",
     "start_time": "2020-03-10T21:57:54.277679Z"
    }
   },
   "outputs": [],
   "source": [
    "# correlation with different topics in the docs\n",
    "sns.pairplot(data=tfidf_nmf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be some correlation between topic 7 with topic 2, and topic 2 with topic 8. It would be interesting to see why"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "delta_env",
   "language": "python",
   "name": "delta_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
